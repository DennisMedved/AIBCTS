{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc19792",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b856a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import tifffile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "import keras_efficientnet_v2\n",
    "import keras\n",
    "import statistics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ed958",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369081d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = \"40\"\n",
    "diffRed = 13\n",
    "dataPath = \"DATA/HTX/\"\n",
    "toolsPath = \"UTILS/\"\n",
    "evalPath = \"EVALUATE\"\n",
    "modelPath = \"MODELS/Model_02.hdf5\"\n",
    "pathProc = \"ProcessedImagesHTX40.txt\"\n",
    "folders = [\"0R\",\"1R\",\"2R\",\"3R\"]\n",
    "batchSize = 320"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498d2ff0",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66340411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readProcessedImages(pathProc):\n",
    "    if os.path.isfile(pathProc):\n",
    "        with open(pathProc) as fp:\n",
    "            setOfPreImages = set(fp.read().splitlines())\n",
    "    else:\n",
    "        print('No ProcessedImages.txt found, converting all images in folder!')\n",
    "        setOfPreImages = set()\n",
    "    return setOfPreImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1156a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDirFiles(inputPath):    \n",
    "    setOfNDPIFiles = set()\n",
    "    for file in os.listdir(inputPath):\n",
    "        setOfNDPIFiles.add(os.path.join(inputPath, file))\n",
    "    return setOfNDPIFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a689a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutFiles(setOfNDPIFiles, setOfPreImages):\n",
    "    return  list(setOfNDPIFiles.difference(setOfPreImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aaf43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFileName(path):\n",
    "    fileName = path.split(\"/\")\n",
    "    lenFile = len(fileName)-1\n",
    "    fileName = fileName[lenFile]\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0e25441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeProcessedImages(file):\n",
    "    with open(pathProc, \"a\") as myfile:\n",
    "        myfile.write(file+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2103ae4",
   "metadata": {},
   "source": [
    "## Create tiles of the TIFF images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fec25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMosaicOfTIFF(outputPath, file, zoom, size):    \n",
    "    fileName = extractFileName(file)\n",
    "    if(os.path.exists(outputPath+fileName+\"/\"+zoom)):\n",
    "        print(\"*** ALREADY EXTRACTED SKIPPING ***\")\n",
    "    else:\n",
    "        print(\"Mosaic of \" + fileName + \" X\"+ zoom +\" started.\")\n",
    "        os.mkdir(outputPath+fileName+\"/\"+zoom)\n",
    "        shutil.copy(outputPath+fileName+\"/\"+fileName+\"_x\"+zoom+\"_z0.tif\", outputPath+fileName+\"/\"+zoom+\"/\")\n",
    "        arguments = [toolsPath+\"tiffmakemosaic\",\"-g\",size+\"x\"+size, outputPath+fileName+\"/\"+zoom+\"/\"+fileName+\"_x\"+zoom+\"_z0.tif\"]\n",
    "        subprocess.call(arguments)\n",
    "        os.remove(outputPath+fileName+\"/\"+zoom+\"/\"+fileName+\"_x\"+zoom+\"_z0.tif\")\n",
    "        print(\"Mosaic of \" + fileName + \" X\"+ zoom +\" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5875b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiling subfolder: 0R\n",
      "Tiling subfolder: 1R\n",
      "Tiling subfolder: 2R\n",
      "Tiling subfolder: 3R\n"
     ]
    }
   ],
   "source": [
    "for f in folders:\n",
    "    print(\"Tiling subfolder: \"+str(f))\n",
    "    folderPath = os.path.join(dataPath,f+\"/\")\n",
    "    start_time = time.time()\n",
    "    ndpi = readDirFiles(folderPath)\n",
    "    proc = readProcessedImages(pathProc)\n",
    "    ndpis = filterOutFiles(ndpi, proc)\n",
    "    for ndpi in ndpis:\n",
    "        start_time2 = time.time()\n",
    "        createMosaicOfTIFF(folderPath, ndpi, zoom, \"300\")\n",
    "        writeProcessedImages(ndpi)\n",
    "        print(\"*** %s minutes ***\" % ((time.time() - start_time2)/60)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ece230",
   "metadata": {},
   "source": [
    "## Filter tiles to keep only those with tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94bbc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTissue(rgb, dif):\n",
    "    red = rgb[:,:,0].mean()\n",
    "    green = rgb[:,:,1].mean()\n",
    "    blue = rgb[:,:,2].mean()\n",
    "    diffGreen = (red > (green + dif)) or (red < (green - dif))\n",
    "    diffBlue = (red > (blue + dif)) or (red < (blue - dif))\n",
    "    return diffGreen or diffBlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0677ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBlankTiles(folderPath, file, zoom, dif, folder):\n",
    "    start_time = time.time()\n",
    "    fileName = extractFileName(file)\n",
    "    pathInput = folderPath+fileName+\"/\"+zoom+\"/\"\n",
    "    pathOutput = evalPath+\"/\"+folder[0]+\"/\"+fileName\n",
    "    os.mkdir(pathOutput)\n",
    "    print(pathOutput)\n",
    "    num = 0\n",
    "    for file in os.listdir(pathInput):\n",
    "        if file.endswith(\".tif\"):\n",
    "            inPath = os.path.join(pathInput, file)\n",
    "            outPath = os.path.join(pathOutput, file)\n",
    "            rgb = tifffile.imread(inPath)\n",
    "            bol = filterTissue(rgb,dif)\n",
    "            if(bol):\n",
    "                shutil.copy(inPath,outPath)\n",
    "                num += 1\n",
    "    if num<1:\n",
    "        print(\"*** Anamoly, none of the tiles are kept! ***\")\n",
    "    print(\"Kept \"+str(num)+ \" files, for \"+fileName+\" X\"+zoom+\"!\")\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3657e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering subfolder: 0R\n",
      "EVALUATE/0/18PL25788-01-02-01 - 2020-02-24 03.57.32\n",
      "Kept 3256 files, for 18PL25788-01-02-01 - 2020-02-24 03.57.32 X40!\n",
      "--- 1.4796868085861206 minutes ---\n",
      "EVALUATE/0/19PL20427-01-02-03 - 2020-03-02 19.06.26\n",
      "Kept 2066 files, for 19PL20427-01-02-03 - 2020-03-02 19.06.26 X40!\n",
      "--- 0.651185139020284 minutes ---\n",
      "EVALUATE/0/16PL27463-01-01-01 - 2020-02-18 19.29.28\n",
      "Kept 50900 files, for 16PL27463-01-01-01 - 2020-02-18 19.29.28 X40!\n",
      "--- 1.5426672577857972 minutes ---\n",
      "EVALUATE/0/14062 01 - 2020-02-18 06.40.29\n",
      "Kept 5101 files, for 14062 01 - 2020-02-18 06.40.29 X40!\n",
      "--- 1.9209152936935425 minutes ---\n",
      "Filtering subfolder: 1R\n",
      "EVALUATE/1/PL10444 1 HTX - 2019-12-16 18.56.57\n",
      "Kept 3194 files, for PL10444 1 HTX - 2019-12-16 18.56.57 X40!\n",
      "--- 1.9783202568689982 minutes ---\n",
      "EVALUATE/1/P842 B HTX - 2019-12-13 13.06.18\n",
      "Kept 3372 files, for P842 B HTX - 2019-12-13 13.06.18 X40!\n",
      "--- 0.7124816536903381 minutes ---\n",
      "EVALUATE/1/PL9625 4 HTX - 2019-12-17 16.39.44\n",
      "Kept 559 files, for PL9625 4 HTX - 2019-12-17 16.39.44 X40!\n",
      "--- 1.0470282951990764 minutes ---\n",
      "EVALUATE/1/19PL00082-01-01-05 - 2020-03-01 19.37.00\n",
      "Kept 11242 files, for 19PL00082-01-01-05 - 2020-03-01 19.37.00 X40!\n",
      "--- 2.265855371952057 minutes ---\n",
      "Filtering subfolder: 2R\n",
      "EVALUATE/2/PL9941-10;9;;HTX; - 2019-12-13 22.31.36\n",
      "Kept 235 files, for PL9941-10;9;;HTX; - 2019-12-13 22.31.36 X40!\n",
      "--- 0.849295973777771 minutes ---\n",
      "EVALUATE/2/17PL06200-01-01-01 - 2020-02-18 23.59.07\n",
      "Kept 10996 files, for 17PL06200-01-01-01 - 2020-02-18 23.59.07 X40!\n",
      "--- 2.5071059187253315 minutes ---\n",
      "EVALUATE/2/18336 A - 2019-10-24 21.15.26\n",
      "Kept 3576 files, for 18336 A - 2019-10-24 21.15.26 X40!\n",
      "--- 1.5608109474182128 minutes ---\n",
      "EVALUATE/2/18PL30484-01-01-09 - 2020-03-01 15.19.52\n",
      "Kept 1639 files, for 18PL30484-01-01-09 - 2020-03-01 15.19.52 X40!\n",
      "--- 1.0035337766011556 minutes ---\n",
      "Filtering subfolder: 3R\n",
      "EVALUATE/3/15305 01 - 2020-02-19 06.33.41\n",
      "Kept 3317 files, for 15305 01 - 2020-02-19 06.33.41 X40!\n",
      "--- 2.280325146516164 minutes ---\n",
      "EVALUATE/3/15046 A - 2019-10-24 16.49.41\n",
      "Kept 2720 files, for 15046 A - 2019-10-24 16.49.41 X40!\n",
      "--- 1.9756396571795145 minutes ---\n",
      "EVALUATE/3/PL4386 7 HTX - 2019-12-17 15.51.57\n",
      "Kept 1174 files, for PL4386 7 HTX - 2019-12-17 15.51.57 X40!\n",
      "--- 0.9517937858899435 minutes ---\n",
      "EVALUATE/3/16PL11853-01-02-01 - 2020-03-02 17.23.01\n",
      "Kept 4560 files, for 16PL11853-01-02-01 - 2020-03-02 17.23.01 X40!\n",
      "--- 1.497308599948883 minutes ---\n"
     ]
    }
   ],
   "source": [
    "for f in folders:\n",
    "    print(\"Filtering subfolder: \"+str(f))\n",
    "    folderPath = os.path.join(dataPath,f+\"/\")\n",
    "    ndpis = readDirFiles(folderPath)\n",
    "    for ndpi in ndpis:\n",
    "        removeBlankTiles(folderPath, ndpi, zoom, diffRed, f)\n",
    "        writeProcessedImages(ndpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc4d43",
   "metadata": {},
   "source": [
    "## Predict and evaluate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a21691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,valPath):\n",
    "    testDataGen = ImageDataGenerator()\n",
    "    nZero = len(next(os.walk(os.path.join(valPath, str(0))))[1])\n",
    "    nOne = len(next(os.walk(os.path.join(valPath, str(1))))[1])\n",
    "    nTwo = len(next(os.walk(os.path.join(valPath, str(2))))[1])\n",
    "    nThree = len(next(os.walk(os.path.join(valPath, str(3))))[1])\n",
    "    nTest = [nZero,nOne,nTwo,nThree]\n",
    "    real = list()\n",
    "    pred = list()   \n",
    "    for i in range(4):\n",
    "        #print(\"Started validating cat: \"+str(i))\n",
    "        for n in range(nTest[i]):\n",
    "            path = os.path.join(valPath, str(i),str(n))\n",
    "                #print(path)\n",
    "            real.append(i)\n",
    "            testGen = testDataGen.flow_from_directory(\n",
    "                path,\n",
    "                batch_size=batchSize,\n",
    "                class_mode=None,\n",
    "                target_size=(300,300),\n",
    "                classes=[''])\n",
    "            preds = model.predict(testGen, verbose = 1)\n",
    "            pred.append(preds)\n",
    "    accMoMax = 0\n",
    "    f1MoMax = 0\n",
    "    moMax = list()\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    for n in range(2,101):\n",
    "        mo = list()\n",
    "        for i in range(len(pred)):\n",
    "            arr = pred[i]\n",
    "            length = len(arr)\n",
    "            m = n\n",
    "            if (length<m):\n",
    "                m = length\n",
    "            ind = np.argpartition(arr.ravel(), -m)[-m:]\n",
    "            row_indices, col_indices = np.unravel_index(ind, arr.shape)\n",
    "            high = arr[row_indices,:]\n",
    "            preds_max = np.argmax(high, axis=1)\n",
    "            mo.append(statistics.mode(preds_max))\n",
    "        accMo = accuracy_score(real,mo)\n",
    "        f1Mo = f1_score(real, mo, average=\"macro\")\n",
    "        if accMo > accMoMax:\n",
    "            accMoMax = accMo\n",
    "            n1 = n\n",
    "            moMax = mo\n",
    "        if f1Mo > f1MoMax:\n",
    "            f1MoMax = f1Mo\n",
    "            n2 = n\n",
    "    print(\"accMoMax: \"+str(accMoMax) + \" at N = \"+ str(n1))\n",
    "    print(\"f1MoMax: \"+str(f1MoMax) + \" at N = \"+ str(n2))\n",
    "    print(classification_report(real, moMax))\n",
    "    pathRes = os.path.join(\"Result.txt\")\n",
    "    resultFile = open(pathRes, \"a\")\n",
    "    resultFile.write(\"*** RESULTS ***\\n\")\n",
    "    resultFile.write(\"accMoMax: \"+str(accMoMax) + \" at N = \"+ str(n1)+\"\\n\")\n",
    "    resultFile.write(\"f1MoMax: \"+str(f1MoMax) + \" at N = \"+ str(n2)+\"\\n\\n\")\n",
    "    resultFile.write(str(classification_report(real, moMax)))\n",
    "    resultFile.write(\"\\n\\n\")\n",
    "    return f1MoMax, accMoMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09167f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_efficientnet_v2.EfficientNetV2S(num_classes=4,pretrained=\"imagenet21k-ft1k\", include_preprocessing=True)\n",
    "model.load_weights(modelPath)\n",
    "print(\"*** Weights loaded:\" + modelPath + \"***\")\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'],\n",
    "    )\n",
    "\n",
    "f1, acc = evaluate(model,evalPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
